import subprocess

import requests
import re
from bs4 import BeautifulSoup
import time
import datetime
from Projet_Fin_Etude.Utilities.ToolBox import *


def extract_urls(url):
    content = requests.get(url).text
    matches = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', content)
    return matches


# check how can we install this github directories
def advanced_extracts_url(url):
    name_package = "photon"
    check_packages_installed(name_package)
    # try:
    result = subprocess.run(["python3", "photon.py", "-u", url], capture_output=True)
    print("Results are saved in the photon directory .")
    print(result)
    return result
    # except IOError:
    #     subprocess.run(["git", "clone", "https://github.com/s0md3v/Photon.git"])
    #     subprocess.run(["cd", "Photon"])
    #     subprocess.run(["pip3", "install", "-r", "requirement."])
    #     result = subprocess.run(["python3", "photon.py", "-u", url], capture_output=True)
    #     print(result)
    #     return result


# Check if can stores more than one phone number
def extract_phone_numbers(url):
    phone_regex = re.compile(r'\b\+?\d{3}[-.]?\d{3}[-.]?\d{4}\b')
    webPage = requests.get(url).text
    results = phone_regex.finditer(webPage)
    matches = []
    for result in results:
        print("Found phone number : ", result.group())
        matches.append(result.group())
    return matches


#TODO : Install on local ,find a way to install in any device
def extract_information_from_phoneN(phone_numbers):
    name_package = "moriarty"
    check_packages_installed(name_package)
    for phone_number in phone_numbers:
        result = subprocess.run(["moriarty", "search", phone_number], capture_output=True)
        # SAVE the results of this scripts .
        print(result.stdout.decode())


# TODO : Install on local ,find a way to install in any device
def extract_advanced_information(url):
    html = requests.get(url).text
    soup = BeautifulSoup(html, 'html.parser')
    social_media_links = soup.find_all('a', href=re.compile('^https://(www\.)?[a-zA-Z0-9._-]+.(com|net|org)$'))
    email_addresses = soup.find_all(text=re.compile(r'[\w\.-]+@[\w\.-]+'))
    phone_numbers = soup.find_all(text=re.compile(r'\d{3}-\d{3}-\d{4}'))

    package1 = "theharvaster"
    check_packages_installed(package1)
    # Use theHarvester to collect information from external sources
    theharvester_output = subprocess.run(['theharvester', '-d', url, '-l', '500', '-b', 'all'],
                                         stdout=subprocess.PIPE).stdout.decode('utf-8')
    package2 = "maltego"
    check_packages_installed(package2)
    # Use Maltego to analyze the website's domain
    maltego_output = subprocess.run(['maltego', '-i', url, '-t', 'domain'], stdout=subprocess.PIPE).stdout.decode(
        'utf-8')
    # Print the advanced information about the website
    print(f"Social media links: {social_media_links}")
    print(f"Email addresses: {email_addresses}")
    print(f"Phone numbers: {phone_numbers}")
    print(f"theHarvester output: {theharvester_output}")
    print(f"Maltego output: {maltego_output}")


# Object can be : url ,phone number ,name every information that we can extract from the url.
def save_output_file_format(objects):
    timestamp = time.strftime("%Y-%m-%d-%H-%M-%S")
    with open(f"outputExtracted{timestamp}.txt", "w") as file:
        for single_object in objects:
            file.write(single_object + "\n")


# Object can be : url ,phone number ,name every information that we can extract from the url.
def save_ouput_html_format(objects):
    timestamp = time.strftime("%Y-%m-%d-%H-%M-%S")
    html_string = "<html>\n<body>\n<ul>\n"
    title = "Default TITLE"  # this should take two value : Phone numbers , URLS
    html_string += "<h1>{}</h1>\n".format(title)
    for single_object in objects:
        html_string += "<li> <a href='{}'>{}</a> </li>\n".format(single_object, single_object)
    html_string += "</ul>\n</body>\n</html>"
    with open(f"urls{timestamp}.html", "w") as file:
        file.write(html_string)

# urls = extract_urls('https://facebook.com')
# print(urls)

# if __name__ == '__main__':
#     options = {
#         1: extract_urls,
#         2: extract_phone_numbers,
#         3: extract_advanced_information,
#     }
#     print("Welcome to this MODE ... Please choose one of the above MODE: ")
#     print("1-Link extractor")
#     print("2-Phones extractor")
#     print("3-Advanced extraction")
#     option = int(input("Enter your choice :"))
#     c_object = input("Please enter a domainName/IP address: ")
#     if option in options:
#         outputs = options[option](c_object)
#         print("Test")
#         advanced_extracts_url(c_object)
#         save_ouput_html_format(outputs)
#     else:
#         print("Please enter the right choice.")
