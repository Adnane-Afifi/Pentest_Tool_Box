import subprocess

import requests
import re
from bs4 import BeautifulSoup
import time
import datetime
from Projet_Fin_Etude.Utilities.ToolBox import *


# Fix photon library
def extract_urls():
    url = input("Enter the url to extract urls from: ")
    content = requests.get(url).text
    matches = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', content)
    return matches


# TODO: Check if we can use photon .. for now that's not working
def advanced_extracts_url():
    url = input("Enter the url to extract urls from: ")
    name_package = "photon"
    check_packages_installed(name_package)
    # try:
    print("Running photon...")
    result = subprocess.run(["python3", "photon.py", "-u", url], capture_output=True)
    print("saving output...")
    print("Results are saved in the photon directory .")
    print(result)
    return result
    # except IOError:
    #     subprocess.run(["git", "clone", "https://github.com/s0md3v/Photon.git"])
    #     subprocess.run(["cd", "Photon"])
    #     subprocess.run(["pip3", "install", "-r", "requirement."])
    #     result = subprocess.run(["python3", "photon.py", "-u", url], capture_output=True)
    #     print(result)
    #     return result


# Check if can stores more than one phone number
def extract_phone_numbers():
    url = input("Enter the url to extract phone numbers from: ")
    print("Extracting phone numbers...")
    phone_regex = re.compile(r'\b\+?\d{3}[-.]?\d{3}[-.]?\d{4}\b')
    webPage = requests.get(url).text
    results = phone_regex.finditer(webPage)
    matches = []
    print("Saving phone numbers...")
    for result in results:
        print("Found phone number : ", result.group())
        matches.append(result.group())
    return matches


# # Projet git a rechcker voir a supprimer  .
# def extract_information_from_phoneN(phone_numbers):
#     name_package = "moriarty"
#     check_packages_installed(name_package)
#     for phone_number in phone_numbers:
#         result = subprocess.run(["moriarty", "search", phone_number], capture_output=True)
#         print(result.stdout.decode())


# TODO :[Optionel]Install on local ,find a way to install in any device && check the format that we get from the html
#  output OU sinon ajouter les instructions dans le readME.
def extract_advanced_information():
    url = input("Enter the url to extract advanced information from: ")
    print("Extracting advanced information...")
    html = requests.get(url).text
    soup = BeautifulSoup(html, 'html.parser')
    print("Performing social_media search...")
    social_media_links = soup.find_all('a', href=re.compile('^https://(www\.)?[a-zA-Z0-9._-]+.(com|net|org)$'))
    print("Performing email address search...")
    email_addresses = soup.find_all(text=re.compile(r'[\w\.-]+@[\w\.-]+'))
    print("Performing Phone number search...")
    phone_numbers = soup.find_all(text=re.compile(r'\d{3}-\d{3}-\d{4}'))

    # package1 = "theharvaster"
    # check_packages_installed(package1)
    print("Running theharvester...")
    theharvester_output = subprocess.run(['theharvester', '-d', url, '-l', '500', '-b', 'all'],
                                         stdout=subprocess.PIPE).stdout.decode('utf-8')
    # Print the advanced information about the website
    print(f"Social media links: {social_media_links}")
    print(f"Email addresses: {email_addresses}")
    print(f"Phone numbers: {phone_numbers}")
    print(f"theHarvester output: {theharvester_output}")
    return theharvester_output


# Object can be : url ,phone number ,name every information that we can extract from the url.
def save_output_file_format(objects):
    timestamp = time.strftime("%Y-%m-%d-%H-%M-%S")
    with open(f"outputExtracted{timestamp}.txt", "w") as file:
        for single_object in objects:
            file.write(single_object + "\n")


# Object can be : url ,phone number ,name every information that we can extract from the url.
def save_ouput_html_format(objects):
    timestamp = time.strftime("%Y-%m-%d-%H-%M-%S")
    html_string = "<html>\n<body>\n<ul>\n"
    title = "Default TITLE"  # this should take two value : Phone numbers , URLS
    html_string += "<h1>{}</h1>\n".format(title)
    for single_object in objects:
        html_string += "<li> <a href='{}'>{}</a> </li>\n".format(single_object, single_object)
    html_string += "</ul>\n</body>\n</html>"
    with open(f"urls{timestamp}.html", "w") as file:
        file.write(html_string)
